{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drn_interactions.interactions.loaders import SpontaneousActivityLoader, StateInteractionsLoader\n",
    "from drn_interactions.interactions.preprocessors import InteractionsPreprocessor\n",
    "from drn_interactions.interactions.pairwise import PairwiseCorr\n",
    "from drn_interactions.interactions.graph_clustering import df_to_graph\n",
    "from drn_interactions.config import Config, ExperimentInfo\n",
    "import numpy as np\n",
    "from drn_interactions.interactions.graph import GraphAttributes, NodeAttributes\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from drn_interactions.io import load_derived_generic, load_distances\n",
    "from drn_interactions.transforms.graph import GraphTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from drn_interactions.plots import PAL_GREY_BLACK\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "fig_dir = Config.fig_dir\n",
    "sns.set_theme(style=\"ticks\", context=\"paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Graph Results\n",
    "\n",
    "- Graph DF (SWP, Avg Clutering etc)\n",
    "- Node (Centrality, NT, Clustering etc)\n",
    "- Edge DF (Weight, Distance, NT Combo, Same NT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_responders():\n",
    "    slow_responders_shock = load_derived_generic(\n",
    "        \"slow_ts_foot_shock_unit_responders_pre_to_shock.csv\"\n",
    "    )[[\"neuron_id\", \"diff_inv\", \"sig\"]].assign(\n",
    "        response_fs_slow=lambda x: np.where(\n",
    "            x[\"sig\"] == False,\n",
    "            \"no_response\",\n",
    "            np.where(x[\"diff_inv\"] < 0, \"inhibited\", \"activated\"),\n",
    "        )\n",
    "    )[[\"neuron_id\", \"response_fs_slow\"]]\n",
    "\n",
    "    fast_responders = load_derived_generic(\"fast_fs_foot_shock_unit_responders.csv\")[\n",
    "        [\"neuron_id\", \"Diff\", \"sig\"]\n",
    "    ].assign(\n",
    "        response_fs_fast=lambda x: np.where(\n",
    "            x[\"sig\"] == False,\n",
    "            \"no_response\",\n",
    "            np.where(x[\"Diff\"] < 0, \"inhibited\", \"activated\"),\n",
    "        )\n",
    "    )[[\"neuron_id\", \"response_fs_fast\"]]\n",
    "\n",
    "    bs_response = load_derived_generic(\"brain_states_spikerate_responders.csv\")[\n",
    "        [\"neuron_id\", \"Diff\", \"sig\"]\n",
    "    ].assign(\n",
    "        response_bs=lambda x: np.where(\n",
    "            x[\"sig\"] == False,\n",
    "            \"no_response\",\n",
    "            np.where(x[\"Diff\"] < 0, \"inhibited\", \"activated\"),\n",
    "        )\n",
    "    )[[\"neuron_id\", \"response_bs\"]]\n",
    "\n",
    "    df_responders = slow_responders_shock.merge(fast_responders, how=\"outer\").merge(bs_response, how=\"outer\")\n",
    "    return df_responders\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_ensembles = load_derived_generic(\"ensembles/spont - ensembles - true.csv\")\n",
    "df_ensembles[\"in_ensemble\"] = np.where(df_ensembles[\"ensemble_id\"] == -1, False, True)\n",
    "\n",
    "graph_attrs = GraphAttributes(inverse_distance=True)\n",
    "node_attrs = NodeAttributes()\n",
    "df_responders = load_responders()\n",
    "neuron_types = load_derived_generic(\"neuron_types.csv\")[\n",
    "    [\"neuron_id\", \"neuron_type\", \"session_name\"]\n",
    "]\n",
    "df_distance = load_distances()\n",
    "sessions = neuron_types[\"session_name\"].dropna().unique()\n",
    "\n",
    "g_transform = GraphTransformer(\n",
    "    relabel_nodes=True,\n",
    "    weight_attr=\"weight\",\n",
    "    neuron_types=neuron_types,\n",
    "    df_distance=df_distance,\n",
    "    df_ensemble=df_ensembles,\n",
    ")\n",
    "graph_dfs = []\n",
    "node_dfs = []\n",
    "node_mappers = []\n",
    "edge_dfs = []\n",
    "\n",
    "for shuffle_higher in (False, True):\n",
    "    for session in sessions:\n",
    "        loader = SpontaneousActivityLoader(\n",
    "            session_name=session, bin_width=1, block=\"pre\", t_start=0, t_stop=1800\n",
    "        )\n",
    "        preprocessor = InteractionsPreprocessor()\n",
    "        pairwise = PairwiseCorr(rectify=True, shuffle=shuffle_higher)\n",
    "\n",
    "        spikes = preprocessor(loader())\n",
    "        df_affinity = (\n",
    "            pairwise.fit(spikes)\n",
    "            .get_adjacency_df()\n",
    "            .dropna(axis=1, thresh=5)\n",
    "            .dropna(axis=0, thresh=5)\n",
    "        )\n",
    "        G = df_to_graph(df_affinity, rename_nodes=True)\n",
    "        graph_stats = graph_attrs.get_graph_attributes(G).assign(session=session, shuffle=shuffle_higher)\n",
    "        node_stats = node_attrs.get_node_attributes(G, node_name=\"neuron_id\").assign(\n",
    "            session=session, shuffle=shuffle_higher\n",
    "        )\n",
    "        edge_stats =g_transform.graph_to_edge_df(G).assign(session=session, shuffle=shuffle_higher)\n",
    "\n",
    "        graph_dfs.append(graph_stats)\n",
    "        node_dfs.append(node_stats)\n",
    "        edge_dfs.append(edge_stats)\n",
    "\n",
    "df_graph = pd.concat(graph_dfs).reset_index(drop=True)\n",
    "df_node = pd.concat(node_dfs).reset_index(drop=True).merge(neuron_types[[\"neuron_id\", \"neuron_type\"]], how=\"left\")\n",
    "df_node = df_node.merge(df_ensembles[[\"neuron_id\", \"in_ensemble\"]], how=\"left\")\n",
    "df_edge = pd.concat(edge_dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Graph Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roryl\\.conda\\envs\\drn-interactions\\lib\\site-packages\\scipy\\stats\\morestats.py:2957: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_False</th>\n",
       "      <th>n_True</th>\n",
       "      <th>Mean_False</th>\n",
       "      <th>Mean_True</th>\n",
       "      <th>Diff</th>\n",
       "      <th>U</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_deg</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_clust</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swp</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.03</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_path_len</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.35</td>\n",
       "      <td>4.69</td>\n",
       "      <td>-30.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              n_False  n_True  Mean_False  Mean_True   Diff      U     p\n",
       "avg_deg          22.0    22.0        4.09       4.10   0.01  123.0  0.92\n",
       "avg_clust        22.0    22.0        0.23       0.17  -0.06    0.0  0.00\n",
       "swp              22.0    22.0        0.37       0.39   0.03   81.0  0.57\n",
       "avg_path_len     22.0    22.0       35.35       4.69 -30.66    1.0  0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pingouin as pg\n",
    "from drn_interactions.stats import mannwhitneyu_plusplus\n",
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "\n",
    "to_compare = [\"avg_deg\", \"avg_clust\", \"swp\", \"avg_path_len\"]\n",
    "\n",
    "def compare_one(df, to_compare, session=\"session_name\", shuffle_col=\"shuffle\"):\n",
    "    dfp = df.pivot(index=session, columns=shuffle_col, values=to_compare)\n",
    "    return mannwhitneyu_plusplus(x=dfp.iloc[:, 0], y=dfp.iloc[:, 1], names=[\"False\", \"True\"], compare_f=wilcoxon)\n",
    "\n",
    "\n",
    "sers = []\n",
    "for col in to_compare:\n",
    "    res = compare_one(df_graph, to_compare=col, session=\"session\", shuffle_col=\"shuffle\")\n",
    "    res.name = col\n",
    "    sers.append(res.to_frame())\n",
    "\n",
    "res_graph = pd.concat(sers, axis=1).T.round(2)\n",
    "display(res_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Node Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.414"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "\n",
    "df = df_node.query(\n",
    "    \"shuffle == False\"\n",
    ")\n",
    "\n",
    "def get_Xy(df, y_col, x_cols=(\"neuron_type\"), shuffle=False):\n",
    "    X = df[x_cols]\n",
    "    y = df[y_col].values\n",
    "    if shuffle:\n",
    "        y = np.random.permutation(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_str, y_str = get_Xy(df.copy(), y_col=\"in_ensemble\", shuffle=False)\n",
    "y = LabelEncoder().fit_transform(y_str)\n",
    "X = OneHotEncoder(sparse=False).fit_transform(X_str.values.reshape(-1, 1))\n",
    "clf = DecisionTreeClassifier(max_depth=10, criterion=\"entropy\")\n",
    "\n",
    "score_true = cross_val_score(\n",
    "    clf, \n",
    "    X, \n",
    "    y, \n",
    "    cv=KFold(shuffle=True), \n",
    "    scoring=\"f1_macro\",).mean()\n",
    "\n",
    "scores_obs = []\n",
    "for i in range(500):\n",
    "    X_str, y_str = get_Xy(df.copy(), y_col=\"in_ensemble\", shuffle=True)\n",
    "    y = LabelEncoder().fit_transform(y_str)\n",
    "    X = OneHotEncoder(sparse=False).fit_transform(X_str.values.reshape(-1, 1))\n",
    "    score = cross_val_score(\n",
    "        clf, \n",
    "        X, \n",
    "        y, \n",
    "        cv=KFold(shuffle=True), \n",
    "        scoring=\"f1_macro\",).mean()\n",
    "    scores_obs.append(score)\n",
    "\n",
    "scores_boot = np.array(scores_obs)\n",
    "np.mean(scores_boot >= score_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_node.query(\n",
    "    \"shuffle == False\"\n",
    ")\n",
    "\n",
    "def get_Xy(df, y_col, x_cols=(\"neuron_type\"), shuffle=False):\n",
    "    X = df[x_cols]\n",
    "    y = df[y_col].values\n",
    "    if shuffle:\n",
    "        y = np.random.permutation(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_str, y = get_Xy(df.copy(), y_col=\"clust\", shuffle=False)\n",
    "\n",
    "X = OneHotEncoder(sparse=False).fit_transform(X_str.values.reshape(-1, 1))\n",
    "clf = DecisionTreeRegressor(max_depth=10)\n",
    "\n",
    "score_true = cross_val_score(\n",
    "    clf, \n",
    "    X, \n",
    "    y, \n",
    "    cv=KFold(shuffle=True), \n",
    "    scoring=\"r2\",).mean()\n",
    "\n",
    "scores_obs = []\n",
    "for i in range(500):\n",
    "    X_str, y = get_Xy(df.copy(), y_col=\"clust\", shuffle=True)\n",
    "    X = OneHotEncoder(sparse=False).fit_transform(X_str.values.reshape(-1, 1))\n",
    "    clf = DecisionTreeRegressor(max_depth=10)\n",
    "    score = cross_val_score(\n",
    "        clf, \n",
    "        X, \n",
    "        y, \n",
    "        cv=KFold(shuffle=True), \n",
    "        scoring=\"r2\",).mean()\n",
    "    scores_obs.append(score)\n",
    "\n",
    "scores_boot = np.array(scores_obs)\n",
    "np.mean(scores_boot >= score_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_node.query(\n",
    "    \"shuffle == False\"\n",
    ")\n",
    "\n",
    "def get_Xy(df, y_col, x_cols=(\"neuron_type\"), shuffle=False):\n",
    "    X = df[x_cols]\n",
    "    y = df[y_col].values\n",
    "    if shuffle:\n",
    "        y = np.random.permutation(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_str, y = get_Xy(df.copy(), y_col=\"degree\", shuffle=False)\n",
    "\n",
    "X = OneHotEncoder(sparse=False).fit_transform(X_str.values.reshape(-1, 1))\n",
    "clf = DecisionTreeRegressor(max_depth=10)\n",
    "\n",
    "score_true = cross_val_score(\n",
    "    clf, \n",
    "    X, \n",
    "    y, \n",
    "    cv=KFold(shuffle=True), \n",
    "    scoring=\"r2\",).mean()\n",
    "\n",
    "scores_obs = []\n",
    "for i in range(500):\n",
    "    X_str, y = get_Xy(df.copy(), y_col=\"degree\", shuffle=True)\n",
    "    X = OneHotEncoder(sparse=False).fit_transform(X_str.values.reshape(-1, 1))\n",
    "    clf = DecisionTreeRegressor(max_depth=10)\n",
    "    score = cross_val_score(\n",
    "        clf, \n",
    "        X, \n",
    "        y, \n",
    "        cv=KFold(shuffle=True), \n",
    "        scoring=\"r2\",).mean()\n",
    "    scores_obs.append(score)\n",
    "\n",
    "scores_boot = np.array(scores_obs)\n",
    "np.mean(scores_boot >= score_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.988138427744215,\n",
       " 0.13614031272622235,\n",
       " 2,\n",
       " array([[ 16.39145907,  77.60854093],\n",
       "        [ 39.58362989, 187.41637011],\n",
       "        [ 42.02491103, 198.97508897]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.crosstab(df[\"neuron_type\"], df[\"in_ensemble\"])\n",
    "chi2_contingency(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>ddof1</th>\n",
       "      <th>ddof2</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>np2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neuron_type</td>\n",
       "      <td>2</td>\n",
       "      <td>559</td>\n",
       "      <td>11.793685</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.040487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source  ddof1  ddof2          F    p-unc       np2\n",
       "0  neuron_type      2    559  11.793685  0.00001  0.040487"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>mean(A)</th>\n",
       "      <th>mean(B)</th>\n",
       "      <th>diff</th>\n",
       "      <th>se</th>\n",
       "      <th>T</th>\n",
       "      <th>p-tukey</th>\n",
       "      <th>hedges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FF</td>\n",
       "      <td>SIR</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FF</td>\n",
       "      <td>SR</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SIR</td>\n",
       "      <td>SR</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B  mean(A)  mean(B)  diff    se     T  p-tukey  hedges\n",
       "0   FF  SIR     0.19     0.13  0.06  0.01  4.40      0.0    0.54\n",
       "1   FF   SR     0.19     0.17  0.02  0.01  1.71      0.2    0.21\n",
       "2  SIR   SR     0.13     0.17 -0.04  0.01 -3.60      0.0   -0.33"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anova = pg.anova(data=df, dv=\"degree\", between=\"neuron_type\")\n",
    "display(anova)\n",
    "pg.pairwise_tukey(data=df, dv=\"degree\", between=\"neuron_type\", ).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>ddof1</th>\n",
       "      <th>ddof2</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>np2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neuron_type</td>\n",
       "      <td>2</td>\n",
       "      <td>559</td>\n",
       "      <td>13.306476</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.045445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source  ddof1  ddof2          F     p-unc       np2\n",
       "0  neuron_type      2    559  13.306476  0.000002  0.045445"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>mean(A)</th>\n",
       "      <th>mean(B)</th>\n",
       "      <th>diff</th>\n",
       "      <th>se</th>\n",
       "      <th>T</th>\n",
       "      <th>p-tukey</th>\n",
       "      <th>hedges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FF</td>\n",
       "      <td>SIR</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FF</td>\n",
       "      <td>SR</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SIR</td>\n",
       "      <td>SR</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-4.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B  mean(A)  mean(B)  diff    se     T  p-tukey  hedges\n",
       "0   FF  SIR     0.24     0.18  0.06  0.01  4.52      0.0    0.55\n",
       "1   FF   SR     0.24     0.23  0.02  0.01  1.48      0.3    0.18\n",
       "2  SIR   SR     0.18     0.23 -0.04  0.01 -4.04      0.0   -0.37"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anova = pg.anova(data=df, dv=\"clust\", between=\"neuron_type\")\n",
    "display(anova)\n",
    "pg.pairwise_tukey(data=df, dv=\"clust\", between=\"neuron_type\", ).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(PAL_GREY_BLACK[::-1])\n",
    "hue_order = [\"SR\", \"SIR\", \"FF\"]\n",
    "f = plt.figure(figsize=(5, 1.2))\n",
    "\n",
    "axes = f.subplots(1, 3, sharex=False, sharey=False)\n",
    "sns.barplot(data=df, x=\"neuron_type\", y=\"degree\", ax=axes[0], order=hue_order, color=\"black\")\n",
    "axes[0].set_xlabel(\"\")\n",
    "axes[0].set_title(\"Neuron\\nNormalized Degree\")\n",
    "axes[0].set_ylabel(\"\")\n",
    "\n",
    "sns.barplot(data=df, x=\"neuron_type\", y=\"clust\", ax=axes[1], order=hue_order, color=\"black\")\n",
    "axes[1].set_xlabel(\"\")\n",
    "axes[1].set_ylabel(\"\")\n",
    "axes[1].set_title(\"Neuron\\nClustering Coefficient\")\n",
    "\n",
    "sns.countplot(data=df, x=\"neuron_type\", hue=\"in_ensemble\", ax=axes[2], order=hue_order)\n",
    "axes[2].set_xlabel(\"\")\n",
    "axes[2].set_ylabel(\"\")\n",
    "axes[2].set_title(\"Count In Ensemble\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.legend().remove()\n",
    "\n",
    "f.subplots_adjust(wspace=0.7)\n",
    "\n",
    "sns.despine(fig=f)\n",
    "f.savefig(fig_dir / \"interactions neuron bars.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Edge Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight ~ distance + nt_comb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "df = df_edge.query(\n",
    "    \"shuffle == False\"\n",
    ")\n",
    "\n",
    "def get_Xy(df, y_col, x_cols=[\"distance\", \"nt_comb\"], shuffle=False):\n",
    "    X = df[x_cols]\n",
    "    y = df[y_col].values\n",
    "    if shuffle:\n",
    "        y = np.random.permutation(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_str, y = get_Xy(df.copy(), y_col=\"weight\", shuffle=False)\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [(\"ohe\", OneHotEncoder(sparse=False), [\"nt_comb\"])],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "X = ct.fit_transform(X_str)\n",
    "\n",
    "\n",
    "clf = DecisionTreeRegressor(max_depth=10)\n",
    "\n",
    "score_true = cross_val_score(\n",
    "    clf, \n",
    "    X, \n",
    "    y, \n",
    "    cv=KFold(shuffle=True), \n",
    "    scoring=\"r2\",).mean()\n",
    "\n",
    "scores_obs = []\n",
    "for i in range(500):\n",
    "    X_str, y = get_Xy(df.copy(), y_col=\"weight\", shuffle=True)\n",
    "    ct = ColumnTransformer(\n",
    "        [(\"ohe\", OneHotEncoder(sparse=False), [\"nt_comb\"])],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    X = ct.fit_transform(X_str)\n",
    "    clf = DecisionTreeRegressor(max_depth=10)\n",
    "    score = cross_val_score(\n",
    "        clf, \n",
    "        X, \n",
    "        y, \n",
    "        cv=KFold(shuffle=True), \n",
    "        scoring=\"r2\",).mean()\n",
    "    scores_obs.append(score)\n",
    "\n",
    "scores_boot = np.array(scores_obs)\n",
    "np.mean(scores_boot >= score_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "df = df_edge.query(\n",
    "    \"shuffle == False\"\n",
    ")\n",
    "\n",
    "def get_Xy(df, y_col, x_cols=[\"distance\", \"nt_comb\"], shuffle=False):\n",
    "    X = df[x_cols]\n",
    "    y = df[y_col].values\n",
    "    if shuffle:\n",
    "        y = np.random.permutation(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_str, y = get_Xy(df.copy(), y_col=\"same_ensemble\", shuffle=False)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [(\"ohe\", OneHotEncoder(sparse=False), [\"nt_comb\"])],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "X = ct.fit_transform(X_str)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "score_true = cross_val_score(\n",
    "    clf, \n",
    "    X, \n",
    "    y, \n",
    "    cv=KFold(shuffle=True), \n",
    "    scoring=\"f1_macro\",).mean()\n",
    "\n",
    "scores_obs = []\n",
    "for i in range(500):\n",
    "    X_str, y = get_Xy(df.copy(), y_col=\"same_ensemble\", shuffle=True)\n",
    "    ct = ColumnTransformer(\n",
    "        [(\"ohe\", OneHotEncoder(sparse=False), [\"nt_comb\"])],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    X = ct.fit_transform(X_str)\n",
    "    clf = DecisionTreeClassifier(max_depth=10)\n",
    "    score = cross_val_score(\n",
    "        clf, \n",
    "        X, \n",
    "        y, \n",
    "        cv=KFold(shuffle=True), \n",
    "        scoring=\"f1_macro\",).mean()\n",
    "    scores_obs.append(score)\n",
    "\n",
    "scores_boot = np.array(scores_obs)\n",
    "np.mean(scores_boot >= score_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('drn-interactions')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "595626f471715c1ef1767721af1162754763b18b459b8364279c934890ae0eae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
